{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and Preprocess Data\n",
    "def load_data_from_psv(folder_path):\n",
    "    \"\"\"Load all .psv files and concatenate into a single DataFrame.\"\"\"\n",
    "    all_files = glob.glob(os.path.join(folder_path, '*.psv'))\n",
    "    data_list = []\n",
    "    for file in all_files:\n",
    "        df = pd.read_csv(file, sep='|')\n",
    "        data_list.append(df)\n",
    "    return pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "# Replace with your folder path\n",
    "data_folder = r'C:\\Users\\uSER\\source\\repos\\alternative-assignment-aml\\training_setA\\training'\n",
    "data = load_data_from_psv(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uSER\\AppData\\Local\\Temp\\ipykernel_19128\\2626206420.py:5: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\uSER\\AppData\\Local\\Temp\\ipykernel_19128\\2626206420.py:6: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Handle Missing Values\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocess the data: handle missing values and normalize.\"\"\"\n",
    "    # Fill missing values (forward fill, then backward fill as fallback)\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "    df.fillna(method='bfill', inplace=True)\n",
    "    df.fillna(0, inplace=True)  # Replace remaining NaNs with 0\n",
    "\n",
    "    # Normalize continuous features\n",
    "    scaler = MinMaxScaler()\n",
    "    continuous_features = [col for col in df.columns if df[col].dtype in [np.float64, np.int64] and col != 'SepsisLabel']\n",
    "    df[continuous_features] = scaler.fit_transform(df[continuous_features])\n",
    "\n",
    "    return df, continuous_features\n",
    "\n",
    "# Preprocess the data\n",
    "data, feature_columns = preprocess_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences_optimized(df, features, target, seq_length):\n",
    "    \"\"\"Efficiently create sequences of data for LSTM input.\"\"\"\n",
    "    data_array = df[features].values  # Convert to NumPy array\n",
    "    target_array = df[target].values  # Convert target to NumPy array\n",
    "\n",
    "    # Ensure sufficient data for sequences\n",
    "    if len(data_array) <= seq_length:\n",
    "        raise ValueError(\"Data length must be greater than the sequence length.\")\n",
    "\n",
    "    num_samples = len(data_array) - seq_length + 1  # Total sequences\n",
    "    X = np.lib.stride_tricks.sliding_window_view(data_array, (seq_length, len(features)))\n",
    "    X = X.reshape(num_samples, seq_length, len(features))  # Adjust shape\n",
    "\n",
    "    y = target_array[seq_length - 1:]  # Align target labels\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# Define sequence length and prepare data\n",
    "sequence_length = 10\n",
    "X, y = create_sequences_optimized(data, feature_columns, 'SepsisLabel', sequence_length)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\uSER\\anaconda3\\envs\\aaa_env\\lib\\site-packages\\keras\\src\\layers\\core\\masking.py:47: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Build LSTM Model\n",
    "def build_lstm_model(input_shape):\n",
    "    \"\"\"Build and compile an LSTM model.\"\"\"\n",
    "    model = Sequential([\n",
    "        Masking(mask_value=0.0, input_shape=input_shape),\n",
    "        LSTM(128, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        LSTM(64),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "model = build_lstm_model(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m19756/19756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 9ms/step - accuracy: 0.9785 - loss: 0.1001 - val_accuracy: 0.9780 - val_loss: 0.0949\n",
      "Epoch 2/10\n",
      "\u001b[1m19756/19756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 9ms/step - accuracy: 0.9787 - loss: 0.0932 - val_accuracy: 0.9780 - val_loss: 0.0931\n",
      "Epoch 3/10\n",
      "\u001b[1m19756/19756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 9ms/step - accuracy: 0.9784 - loss: 0.0931 - val_accuracy: 0.9780 - val_loss: 0.0937\n",
      "Epoch 4/10\n",
      "\u001b[1m19756/19756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 8ms/step - accuracy: 0.9784 - loss: 0.0921 - val_accuracy: 0.9780 - val_loss: 0.0928\n",
      "Epoch 5/10\n",
      "\u001b[1m19756/19756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 8ms/step - accuracy: 0.9783 - loss: 0.0920 - val_accuracy: 0.9780 - val_loss: 0.0921\n",
      "Epoch 6/10\n",
      "\u001b[1m19756/19756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 8ms/step - accuracy: 0.9781 - loss: 0.0918 - val_accuracy: 0.9780 - val_loss: 0.0922\n",
      "Epoch 7/10\n",
      "\u001b[1m19756/19756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 8ms/step - accuracy: 0.9784 - loss: 0.0908 - val_accuracy: 0.9780 - val_loss: 0.0903\n",
      "Epoch 8/10\n",
      "\u001b[1m19756/19756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 8ms/step - accuracy: 0.9786 - loss: 0.0887 - val_accuracy: 0.9780 - val_loss: 0.0906\n",
      "Epoch 9/10\n",
      "\u001b[1m19756/19756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 8ms/step - accuracy: 0.9781 - loss: 0.0895 - val_accuracy: 0.9780 - val_loss: 0.0887\n",
      "Epoch 10/10\n",
      "\u001b[1m19756/19756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 8ms/step - accuracy: 0.9782 - loss: 0.0882 - val_accuracy: 0.9780 - val_loss: 0.0878\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4939/4939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - accuracy: 0.9783 - loss: 0.0864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.08781257271766663, Test Accuracy: 0.977961540222168\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Evaluate the Model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"Evaluate the LSTM model.\"\"\"\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')\n",
    "\n",
    "evaluate_model(model, X_test, y_test)\n",
    "\n",
    "# Step 7: Save the Model\n",
    "model.save('sepsis_lstm_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aaa_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
